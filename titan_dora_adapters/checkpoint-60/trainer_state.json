{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.18181818181818182,
      "grad_norm": 2.9389092922210693,
      "learning_rate": 0.0,
      "loss": 3.3243,
      "step": 1
    },
    {
      "epoch": 0.36363636363636365,
      "grad_norm": 3.525682210922241,
      "learning_rate": 4e-05,
      "loss": 2.9237,
      "step": 2
    },
    {
      "epoch": 0.5454545454545454,
      "grad_norm": 3.1256120204925537,
      "learning_rate": 8e-05,
      "loss": 2.5526,
      "step": 3
    },
    {
      "epoch": 0.7272727272727273,
      "grad_norm": 2.790163278579712,
      "learning_rate": 0.00012,
      "loss": 2.5719,
      "step": 4
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 2.0544064044952393,
      "learning_rate": 0.00016,
      "loss": 2.2032,
      "step": 5
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.034247875213623,
      "learning_rate": 0.0002,
      "loss": 1.894,
      "step": 6
    },
    {
      "epoch": 1.1818181818181819,
      "grad_norm": 1.0075777769088745,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.9705,
      "step": 7
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 0.8263733983039856,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.7627,
      "step": 8
    },
    {
      "epoch": 1.5454545454545454,
      "grad_norm": 0.9031591415405273,
      "learning_rate": 0.0001890909090909091,
      "loss": 2.3623,
      "step": 9
    },
    {
      "epoch": 1.7272727272727273,
      "grad_norm": 0.7263782024383545,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.7867,
      "step": 10
    },
    {
      "epoch": 1.9090909090909092,
      "grad_norm": 0.6170592308044434,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.9107,
      "step": 11
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6062936782836914,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.7425,
      "step": 12
    },
    {
      "epoch": 2.1818181818181817,
      "grad_norm": 0.48582884669303894,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.5582,
      "step": 13
    },
    {
      "epoch": 2.3636363636363638,
      "grad_norm": 0.47584033012390137,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.6788,
      "step": 14
    },
    {
      "epoch": 2.5454545454545454,
      "grad_norm": 0.5330639481544495,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.9376,
      "step": 15
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 0.4330582022666931,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.359,
      "step": 16
    },
    {
      "epoch": 2.909090909090909,
      "grad_norm": 0.4557355046272278,
      "learning_rate": 0.00016,
      "loss": 1.2803,
      "step": 17
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.4944896399974823,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.6315,
      "step": 18
    },
    {
      "epoch": 3.1818181818181817,
      "grad_norm": 0.539056658744812,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.6106,
      "step": 19
    },
    {
      "epoch": 3.3636363636363638,
      "grad_norm": 0.39323148131370544,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.3911,
      "step": 20
    },
    {
      "epoch": 3.5454545454545454,
      "grad_norm": 0.5098015069961548,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.7639,
      "step": 21
    },
    {
      "epoch": 3.7272727272727275,
      "grad_norm": 0.49639734625816345,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.7374,
      "step": 22
    },
    {
      "epoch": 3.909090909090909,
      "grad_norm": 0.35802170634269714,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.0409,
      "step": 23
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.4154658019542694,
      "learning_rate": 0.00013454545454545455,
      "loss": 0.9709,
      "step": 24
    },
    {
      "epoch": 4.181818181818182,
      "grad_norm": 0.4338633418083191,
      "learning_rate": 0.00013090909090909093,
      "loss": 1.277,
      "step": 25
    },
    {
      "epoch": 4.363636363636363,
      "grad_norm": 0.5473524332046509,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.5509,
      "step": 26
    },
    {
      "epoch": 4.545454545454545,
      "grad_norm": 0.3770516514778137,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.2483,
      "step": 27
    },
    {
      "epoch": 4.7272727272727275,
      "grad_norm": 0.4793340861797333,
      "learning_rate": 0.00012,
      "loss": 1.2764,
      "step": 28
    },
    {
      "epoch": 4.909090909090909,
      "grad_norm": 0.3602431118488312,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.0262,
      "step": 29
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.6742538809776306,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.538,
      "step": 30
    },
    {
      "epoch": 5.181818181818182,
      "grad_norm": 0.5520692467689514,
      "learning_rate": 0.00010909090909090909,
      "loss": 1.2992,
      "step": 31
    },
    {
      "epoch": 5.363636363636363,
      "grad_norm": 0.43854594230651855,
      "learning_rate": 0.00010545454545454545,
      "loss": 1.2128,
      "step": 32
    },
    {
      "epoch": 5.545454545454545,
      "grad_norm": 0.46606341004371643,
      "learning_rate": 0.00010181818181818181,
      "loss": 1.2838,
      "step": 33
    },
    {
      "epoch": 5.7272727272727275,
      "grad_norm": 0.36004647612571716,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.8907,
      "step": 34
    },
    {
      "epoch": 5.909090909090909,
      "grad_norm": 0.46579620242118835,
      "learning_rate": 9.454545454545455e-05,
      "loss": 1.1681,
      "step": 35
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.74505615234375,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.3559,
      "step": 36
    },
    {
      "epoch": 6.181818181818182,
      "grad_norm": 0.4604445993900299,
      "learning_rate": 8.727272727272727e-05,
      "loss": 1.0559,
      "step": 37
    },
    {
      "epoch": 6.363636363636363,
      "grad_norm": 0.5674313306808472,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.2407,
      "step": 38
    },
    {
      "epoch": 6.545454545454545,
      "grad_norm": 0.42305827140808105,
      "learning_rate": 8e-05,
      "loss": 0.9578,
      "step": 39
    },
    {
      "epoch": 6.7272727272727275,
      "grad_norm": 0.47803622484207153,
      "learning_rate": 7.636363636363637e-05,
      "loss": 1.0322,
      "step": 40
    },
    {
      "epoch": 6.909090909090909,
      "grad_norm": 0.558924674987793,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.1292,
      "step": 41
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.6165065169334412,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.0417,
      "step": 42
    },
    {
      "epoch": 7.181818181818182,
      "grad_norm": 0.4412451684474945,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.8799,
      "step": 43
    },
    {
      "epoch": 7.363636363636363,
      "grad_norm": 0.5779951214790344,
      "learning_rate": 6.181818181818182e-05,
      "loss": 1.1892,
      "step": 44
    },
    {
      "epoch": 7.545454545454545,
      "grad_norm": 0.4978760778903961,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.9988,
      "step": 45
    },
    {
      "epoch": 7.7272727272727275,
      "grad_norm": 0.5691166520118713,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 1.0326,
      "step": 46
    },
    {
      "epoch": 7.909090909090909,
      "grad_norm": 0.5647268891334534,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.858,
      "step": 47
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.7605623602867126,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.0209,
      "step": 48
    },
    {
      "epoch": 8.181818181818182,
      "grad_norm": 0.6455309987068176,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.1231,
      "step": 49
    },
    {
      "epoch": 8.363636363636363,
      "grad_norm": 0.6640832424163818,
      "learning_rate": 4e-05,
      "loss": 0.9635,
      "step": 50
    },
    {
      "epoch": 8.545454545454545,
      "grad_norm": 0.7154880166053772,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.163,
      "step": 51
    },
    {
      "epoch": 8.727272727272727,
      "grad_norm": 0.520888090133667,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.7285,
      "step": 52
    },
    {
      "epoch": 8.909090909090908,
      "grad_norm": 0.5286862850189209,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.8712,
      "step": 53
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.5376054644584656,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 0.7132,
      "step": 54
    },
    {
      "epoch": 9.181818181818182,
      "grad_norm": 0.8157027363777161,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 1.2337,
      "step": 55
    },
    {
      "epoch": 9.363636363636363,
      "grad_norm": 0.6206375956535339,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.8964,
      "step": 56
    },
    {
      "epoch": 9.545454545454545,
      "grad_norm": 0.6583290100097656,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.9309,
      "step": 57
    },
    {
      "epoch": 9.727272727272727,
      "grad_norm": 0.4445890188217163,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.6593,
      "step": 58
    },
    {
      "epoch": 9.909090909090908,
      "grad_norm": 0.5188601016998291,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.8514,
      "step": 59
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.8436082601547241,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.8825,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1200571103109120.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
